{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"tutorial1.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMKoLnG6/wVIO6XcYO+XKit"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["# If you don't use Colab, please ignore this part\n","# This mounts your Google Drive to the Colab VM.\n","from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)\n","\n","# Enter the foldername in your Drive where you have saved the script and dataset\n","FOLDERNAME = 'SMM636/'\n","assert FOLDERNAME is not None, \"[!] Enter the foldername.\"\n","\n","# Now that we've mounted your Drive, this ensures that\n","# the Python interpreter of the Colab VM can load\n","# python files from within it.\n","import sys\n","sys.path.append('/content/drive/My Drive/{}'.format(FOLDERNAME))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MqB7SNgHkWIF","executionInfo":{"status":"ok","timestamp":1643201332571,"user_tz":0,"elapsed":21990,"user":{"displayName":"Rui Zhu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01006588934350664975"}},"outputId":"9ead8b0c-3014-4b52-e6f5-6cb74c894c80"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["# **Titanic - Machine Learning from Disaster**\n","\n","* This task is to predict survival on the Titanic, which is a challenge provided by Kaggle: 'https://www.kaggle.com/c/titanic/overview'. The training set and test set are already split for you to use.\n","\n","* There are ten variables in this dataset: \n","\n","  **One Label**: *Survival*: 0=No, 1=Yes\n","\n","  **Nine Features**:\n","  *pclass* (ticket class); *sex*; *age*; *sibsp* (# of siblings / spouses aboard); *parch* (# of parents / children aboard); *ticket* (ticket number); *fare* (passenger fare); *cabin* (cabin number); *embarked* (port of embarkation, C=Cherbourg, Q=Queenstown, S=Southampton)\n","\n","* This exercise is to get familiar with using Python for classification, so we just use two features in the dataset for illustration purpose."],"metadata":{"id":"dLZ-GOZ3qL-p"}},{"cell_type":"markdown","source":["# **Logistic regression via `sklearn`**"],"metadata":{"id":"-ZmialSgBC2I"}},{"cell_type":"code","source":["import pandas as pd\n","# load training data \n","train = pd.read_csv()\n","# have a look at the training data\n"],"metadata":{"id":"LyjylLDJn5DK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# get feature matrix of training set\n","\n","# DataFrame.loc: Access a group of rows and columns by label(s) or a boolean array.\n","# 'https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.loc.html'\n"],"metadata":{"id":"bpXpAHuivOUY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# get labels of training set\n"],"metadata":{"id":"G-TbBGmQwmae"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# build a logistic regression model\n","from sklearn.linear_model import LogisticRegression\n","# initialise a logistic regression model\n","# by default a penalty term is added \n","# train the model by the training feature matrix and labels\n","\n","# or combine the previous two steps in one line, the results are the same\n"],"metadata":{"id":"mY8tIjlGx6uS","executionInfo":{"status":"ok","timestamp":1643201349522,"user_tz":0,"elapsed":802,"user":{"displayName":"Rui Zhu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01006588934350664975"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["# have a look at the estimated coefficients and intercept\n"],"metadata":{"id":"bpjcQtxs0k9x"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# import the test set\n","test = pd.read_csv()\n","# get the feature matrix of test set\n","\n","# note that there are no labels in test set, so we can only have our predictions, but cannot know how\n","# the classifier performs"],"metadata":{"id":"Yi9Bh4Cl07Ph","executionInfo":{"status":"ok","timestamp":1643201357907,"user_tz":0,"elapsed":548,"user":{"displayName":"Rui Zhu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01006588934350664975"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["# get prediction of survival from logistic regression\n"],"metadata":{"id":"wQDye0q02HsJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Logistic regression via `statsmodels`**"],"metadata":{"id":"22gVGcJgBXhy"}},{"cell_type":"code","source":["# however, as a statistical model, we usually want to have an easy access to the estimated coefficients,\n","# their p-values and other statistical quantities, as what we can easily have in R\n","# in this case, I would recommend to use the statsmodels library\n","# 'https://www.statsmodels.org/dev/examples/notebooks/generated/glm.html'\n","import statsmodels.api as sm\n","# we need to manually add a constant column to include intercept in regression\n","\n","# fit a GLM model with binomial family\n"],"metadata":{"id":"V50UEGp84qxT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# predict for test set\n","\n","# here we have the scores (posterior probability) rather than labels from prediction"],"metadata":{"id":"5ERlqNAr97Qs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# transform scores to labels: <0.5 --> 0; >0.5 --> 1\n"],"metadata":{"id":"fDKhRxBJ_CfU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# ***k*NN via `sklearn`**\n","\n","In this part, we are goint to know how to get training/test splits by `train_test_split` function. Thus we are going to use the training set only."],"metadata":{"id":"lBzqawYzsDj7"}},{"cell_type":"code","source":["import numpy as np\n","from sklearn import neighbors\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score"],"metadata":{"id":"pttpiCkitDvY","executionInfo":{"status":"ok","timestamp":1643201381412,"user_tz":0,"elapsed":220,"user":{"displayName":"Rui Zhu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01006588934350664975"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["# We now name the matrices X and y to avoid confusion. We are going to split the dataset to a training and test set.\n"],"metadata":{"id":"GxYVXjaSuptt","executionInfo":{"status":"ok","timestamp":1643201383483,"user_tz":0,"elapsed":213,"user":{"displayName":"Rui Zhu","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"01006588934350664975"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["\n","# how to check how many training instances for each class?\n"],"metadata":{"id":"vJYOHT07yo7_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# build a knn classifier based on the training set\n"],"metadata":{"id":"lxUDfqggzWYW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# predict the test set\n","\n","# get the predicted probabilities for each class\n","\n","# have a look at the prediction\n","\n","# get the accuracy\n"],"metadata":{"id":"rrCOUbaSzbyZ"},"execution_count":null,"outputs":[]}]}